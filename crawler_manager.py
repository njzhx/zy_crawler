import time
from datetime import datetime

# ==========================================
# çˆ¬è™«ç®¡ç†ç³»ç»Ÿ
# åŠŸèƒ½ï¼šæ‰§è¡Œå¤šä¸ªçˆ¬è™«ï¼Œä¸€ä¸ªçˆ¬è™«å‡ºé”™ä¸å½±å“å…¶ä»–çˆ¬è™«
# ==========================================

class CrawlerManager:
    def __init__(self):
        """åˆå§‹åŒ–çˆ¬è™«ç®¡ç†å™¨"""
        self.crawlers = []
        self.results = {}
    
    def register_crawler(self, name, crawler_func):
        """æ³¨å†Œçˆ¬è™«
        
        Args:
            name: çˆ¬è™«åç§°
            crawler_func: çˆ¬è™«æ‰§è¡Œå‡½æ•°
        """
        self.crawlers.append((name, crawler_func))
        print(f"âœ… å·²æ³¨å†Œçˆ¬è™«: {name}")
    
    def run_all_crawlers(self):
        """æ‰§è¡Œæ‰€æœ‰çˆ¬è™«
        
        Returns:
            dict: å„çˆ¬è™«æ‰§è¡Œç»“æœ
        """
        print(f"\nğŸš€ å¼€å§‹æ‰§è¡Œçˆ¬è™«ä»»åŠ¡ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 60)
        
        total_start_time = time.time()
        
        for name, crawler_func in self.crawlers:
            print(f"\nğŸ“¦ å¼€å§‹æ‰§è¡Œçˆ¬è™«: {name}")
            print("-" * 40)
            
            start_time = time.time()
            
            try:
                # æ‰§è¡Œçˆ¬è™«
                result = crawler_func()
                
                # è®°å½•ç»“æœ
                execution_time = time.time() - start_time
                self.results[name] = {
                    'status': 'success',
                    'data_count': len(result),
                    'execution_time': round(execution_time, 2),
                    'timestamp': datetime.now().isoformat()
                }
                
                print(f"âœ… çˆ¬è™« {name} æ‰§è¡ŒæˆåŠŸ")
                print(f"ğŸ“Š æŠ“å–æ•°æ®: {len(result)} æ¡")
                print(f"â±ï¸  æ‰§è¡Œæ—¶é—´: {round(execution_time, 2)} ç§’")
                
            except Exception as e:
                # æ•è·å¼‚å¸¸ï¼Œç¡®ä¿å…¶ä»–çˆ¬è™«ç»§ç»­æ‰§è¡Œ
                execution_time = time.time() - start_time
                self.results[name] = {
                    'status': 'error',
                    'error_message': str(e),
                    'execution_time': round(execution_time, 2),
                    'timestamp': datetime.now().isoformat()
                }
                
                print(f"âŒ çˆ¬è™« {name} æ‰§è¡Œå¤±è´¥")
                print(f"ğŸ’¥ é”™è¯¯ä¿¡æ¯: {str(e)}")
                print(f"â±ï¸  æ‰§è¡Œæ—¶é—´: {round(execution_time, 2)} ç§’")
            
            print("-" * 40)
        
        total_execution_time = time.time() - total_start_time
        
        print("=" * 60)
        print(f"ğŸ“‹ çˆ¬è™«æ‰§è¡Œå®Œæˆ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"â±ï¸  æ€»æ‰§è¡Œæ—¶é—´: {round(total_execution_time, 2)} ç§’")
        print(f"ğŸ“¦ æ‰§è¡Œçˆ¬è™«æ•°: {len(self.crawlers)}")
        
        # ç»Ÿè®¡ç»“æœ
        success_count = sum(1 for r in self.results.values() if r['status'] == 'success')
        error_count = sum(1 for r in self.results.values() if r['status'] == 'error')
        
        print(f"âœ… æˆåŠŸ: {success_count} ä¸ª")
        print(f"âŒ å¤±è´¥: {error_count} ä¸ª")
        
        return self.results
    
    def get_summary(self):
        """è·å–æ‰§è¡Œæ‘˜è¦"""
        if not self.results:
            return "å°šæœªæ‰§è¡Œçˆ¬è™«ä»»åŠ¡"
        
        summary = []
        for name, result in self.results.items():
            if result['status'] == 'success':
                summary.append(f"âœ… {name}: æˆåŠŸæŠ“å– {result['data_count']} æ¡æ•°æ®")
            else:
                summary.append(f"âŒ {name}: æ‰§è¡Œå¤±è´¥ - {result['error_message'][:100]}...")
        
        return "\n".join(summary)

# ==========================================
# ä¸»æ‰§è¡Œé€»è¾‘
# ==========================================
if __name__ == "__main__":
    # åˆ›å»ºçˆ¬è™«ç®¡ç†å™¨
    manager = CrawlerManager()
    
    # æ³¨å†Œçˆ¬è™«
    # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦æ ¹æ®å®é™…çˆ¬è™«æ¨¡å—è¿›è¡Œå¯¼å…¥å’Œæ³¨å†Œ
    try:
        # å¯¼å…¥ä¸­å›½æ”¿åºœç½‘çˆ¬è™«
        import gov_crawler
        manager.register_crawler("ä¸­å›½æ”¿åºœç½‘", gov_crawler.run)
        
        # å¯¼å…¥æµ‹è¯•çˆ¬è™«ï¼ˆç”¨äºæµ‹è¯•é”™è¯¯å¤„ç†ï¼‰
        import test_crawler
        manager.register_crawler("æµ‹è¯•çˆ¬è™«", test_crawler.run)
        
        # åç»­æ·»åŠ å…¶ä»–çˆ¬è™«æ—¶ï¼ŒæŒ‰ç…§ä»¥ä¸‹æ ¼å¼æ³¨å†Œ
        # import other_crawler
        # manager.register_crawler("å…¶ä»–ç½‘ç«™", other_crawler.run)
        
    except ImportError as e:
        print(f"âš ï¸  å¯¼å…¥çˆ¬è™«æ¨¡å—å¤±è´¥: {e}")
    
    # æ‰§è¡Œæ‰€æœ‰çˆ¬è™«
    if manager.crawlers:
        results = manager.run_all_crawlers()
        
        # æ‰“å°æ‰§è¡Œæ‘˜è¦
        print("\nğŸ“Š æ‰§è¡Œæ‘˜è¦:")
        print("=" * 60)
        print(manager.get_summary())
    else:
        print("âš ï¸  æ²¡æœ‰æ³¨å†Œä»»ä½•çˆ¬è™«")
