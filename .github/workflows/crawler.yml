name: 政策爬虫定时执行

on:
  schedule:
    # 北京时间凌晨3点整（UTC时间前一天19:00）
    - cron: '0 19 * * *'
  workflow_dispatch:
    # 允许手动触发

jobs:
  crawl:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
      - name: 检出代码
        uses: actions/checkout@v4
      
      - name: 设置 DNS（使用 114.114.114.114）
        run: |
          echo "===== 修改 DNS ====="
          sudo systemctl stop systemd-resolved || true
          sudo rm -f /etc/resolv.conf
          echo "nameserver 114.114.114.114" | sudo tee /etc/resolv.conf
          echo "===== 当前 DNS 配置 ====="
          cat /etc/resolv.conf
      
      - name: 设置 Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
      
      - name: 安装系统依赖（Chrome）
        run: |
          sudo apt-get update
          sudo apt-get install -y chromium-browser chromium-chromedriver
      
      - name: 安装依赖
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: 执行爬虫
        run: python crawler_manager.py
        env:
          SUPABASE_PROJECT_API: ${{ secrets.SUPABASE_PROJECT_API }}
          SUPABASE_ANON_PUBLIC: ${{ secrets.SUPABASE_ANON_PUBLIC }}
          FEISHU_BOT_WEBHOOK: ${{ secrets.FEISHU_BOT_WEBHOOK }}
      
      - name: 输出执行结果
        if: always()
        run: echo "爬虫执行完成，请查看上方日志"
