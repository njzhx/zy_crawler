name: 政策爬虫定时执行

on:
  schedule:
    # 北京时间凌晨3点整（UTC时间前一天19:00）
    - cron: '0 19 * * *'
  workflow_dispatch:
    # 允许手动触发

jobs:
  crawl:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
      - name: 检出代码
        uses: actions/checkout@v4
      
      - name: 设置 Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
      
      - name: DNS Test
        run: |
          nslookup www.mohurd.gov.cn 1.1.1.1
              
      - name: 安装系统依赖（Chrome）
        run: |
          sudo apt-get update
          sudo apt-get install -y chromium-browser chromium-chromedriver
      
      - name: 安装依赖
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: 执行爬虫
        run: python crawler_manager.py
        env:
          # Supabase 环境变量（需要在 GitHub 仓库设置 Secrets）
          SUPABASE_PROJECT_API: ${{ secrets.SUPABASE_PROJECT_API }}
          SUPABASE_ANON_PUBLIC: ${{ secrets.SUPABASE_ANON_PUBLIC }}
          # 飞书机器人 Webhook（需要在 GitHub 仓库设置 Secrets）
          FEISHU_BOT_WEBHOOK: ${{ secrets.FEISHU_BOT_WEBHOOK }}
      
      - name: 输出执行结果
        if: always()
        run: echo "爬虫执行完成，请查看上方日志"
